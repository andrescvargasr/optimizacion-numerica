{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P0_Intro_Opt.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN22qaB18/DVNzgFzT3HPBw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"go6B5UnzGpON","colab_type":"text"},"source":["# **710077 - Optimización Numérica**\n","# Parte # 1. Optimización sin Restricciones\n","\n","<img style=\"float: right; padding-right: 10px;\" height=\"220\" src=\"http://mafalda.univalle.edu.co/simbolos/logos/imagenes/univalle-wrc.gif\"> <br>\n","\n","**Universidad del Valle** <br>\n","**Escuela de Ingeniería Eléctrica y Electrónica** <br>\n","**Área de Informática Industrial** <br>\n","\n","**Profesor:** Wilfredo Alfonso Morales, Ph.D. <br>"]},{"cell_type":"markdown","metadata":{"id":"T7vl0sK0HIAD","colab_type":"text"},"source":["# 1. Introducción ([Bertsekas, 2008](http://venus.unive.it/~fasano/Nonlinear_Programming_IIed.pdf))\n","\n","Los modelos matemáticos de optimización pueden ser generalmente representados por:\n","\n","* El conjunto de restricciones $X$\n","* Una función de costo $f$ (mapea los elementos de $X$ dentro de los números reales)\n","\n","Lo que se busca es encontrar una decisión óptima, es decir, un $x^{*} \\in X$ tal que:\n","\n","$f\\left(x^{*}\\right)\\leq f\\left(x\\right)$, $\\forall x \\in X$\n","\n","El problema de optimización entonces se define como:\n","\n","$minimizar ~ f\\left(x \\right)$\n","\n","$s.t. ~ x \\in X$\n","\n","$x$ es un vector $n$-dimensional, o una $n$-tupla de números reales $\\left(x_{1},x_{2},\\ldots,x_{n}\\right)$. El conjunto de restricciones $X$ es un subconjunto de $\\mathbb{R}^{n}$, es decir el espacio Euclideano $n$-dimensional.\n","\n","La función $f:\\mathbb{R}^{n} \\to \\mathbb{R}$ que deseamos minimizar es una función de valor real llamada *función de costo* o *función objetivo*. El valor $x \\in \\mathbb{R}^{n}$ es un vector columna:\n","\n","$x = \\left[ x_{1},x_{2},\\ldots,x_{n}\\right] ^{T}$\n","\n","donde cada elemento del vector es conocido como *variable de decisión*.\n","\n","$X$ es un subconjunto de $\\mathbb{R}^{n}$ es llamado *conjunto de restricciones* o *conjuto factible*.\n","\n","<center>\n","<table>\n","<th><img src=\"https://www.researchgate.net/profile/Jean-Bernard_Lasserre/publication/4006246/figure/fig1/AS:654096461742081@1532960157285/Six-hump-camel-back-function_W640.jpg\" height=\"350\"></th>\n","<th><img src=\"https://nlopt.readthedocs.io/en/latest/images/NLopt-example-constraints.png\" height=\"350\"></th>\n","</center>\n","\n","<center>\n","<img src=\"https://i.stack.imgur.com/BUT7I.png\" height=\"500\">\n","</center>\n","\n","El problema de optimización puede ser visto como un problema de decisión que involucra hallar el mejor vector $x$ de las variables de decisión de todos los posibles vectores en $X$. Por *\"el mejor\"* se entiende que uno da como resultado el valor más pequeño (grande) de la función objetivo. Este vector es llamado el **minimizador (maximizador) de $f$ sobfre $X$**. Es posible que haya muchos minimizadores. En este caso hallar alguno de los minimizadores será suficiente. Minimizadores o maximizadores son llamados también **extremizadores** y depende del problema lo que se desea hallar.\n","\n","En general, cualquiera sea el problema se cumple que:\n","\n","$\\min f = \\max -f$\n","\n","Por lo tanto, todos los problemas se pueden tratar como problemas de minimización sin perder generalidad.\n","\n","La definición del optimización hasta este momento ha sido presentada de manera general como un **problema de optimización con restricciones** porque las variables de decisión están restringidas a estar dentro del conjunto $X$. Un problema de optimización donde no hay restricciones se puede entender como $X=\\mathbb{R}^{n}$.\n"]},{"cell_type":"markdown","metadata":{"id":"iKSDQOB261ow","colab_type":"text"},"source":["# 2. Optimización sin Restricciones \n","\n","Primero es importante identificar cuales son las condiciones para identificar un mínimo.\n","\n","<center>\n","<img src=\"https://drive.google.com/uc?id=12uLQwHcMqisXDuknDLRH6BMWrUjj1oSq\" height=\"350\">\n","</center>\n","\n","Del gráfico podemos identificar tres tipos de minimizadores:\n","\n","* $x_{1}$ Es estrictamente un minimizador global.\n","* $x_{2}$ Es estrictamente un minimizador local.\n","* $x_{3}$ Es un minimizador local (no-estricto) **Por qué?** "]},{"cell_type":"markdown","metadata":{"id":"xSbT6qL30U25","colab_type":"text"},"source":["## 2.1. Mínimo Global sin Restricciones\n","\n","Si $x^{*} \\in \\mathbb{R}^{n}$ cumple que:\n","\n","$f\\left(x^{*}\\right) \\leq f\\left(x\\right) ~ \\forall x \\in \\mathbb{R}^{n}$\n","\n","Por otro lado, si se reemplaza el símbolo \"$\\leq$\" por \"$<$\" la solución es estrictamente un mínimo global o minimizador global estricto $\\forall x \\neq x^{*}$\n","\n","## 2.2. Mínimo Local sin Restricciones\n","\n","En este caso se define:\n","\n","$\\exists \\epsilon > 0$ tal que:\n","\n","$f\\left(x^{*}\\right) \\leq f\\left(x\\right) ~ \\forall x \\in \\mathbb{R}^{n} ~ \\text{y además,} ~ \\|x-x^{*}\\| < \\epsilon$\n","\n","($\\|y\\|$ significa la norma (base 2) de $y \\in \\mathbb{R}^{n}$ = $\\sqrt{y^{T}\\cdot y}$)\n","\n","Fácilmente podemos convertir un problema de optimización sin restricciones a uno con restricciones, si consideramos que el conjunto de soluciones esta restringido por el conjunto $X$. En el sentido contrario, es decir para un problema sin restricciones, tomamos lo que presentamos anteriormente: $X=\\mathbb{R}^{n}$.\n","\n","Así cualquier problema sin restricciones pasa a ser uno con restricciones cuando $x^{*} \\in \\mathbb{R}^{n}$ se reemplaza por $x^{*} \\in X$ o se puede representar también como $\\forall x \\in \\mathbb{R}^{n}$ reemplazandose por $\\forall x \\in X$.\n","\n","<center>\n","<img src=\"https://www.mathworks.com/help/examples/optim/win64/tutdemo_01.png\" height=\"350\">\n","</center>\n","\n","Si $x^{*}$ es un minimizador global de $f$ en $X$, entonces:\n","\n","| Funciones &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | Definición                                        |\n","|------------------------------------------------------------------------------------------------------------------------------ | ----------------------------- |\n","| <ul><li>$f\\left(x^{*}\\right) = \\min_{x \\in X} f\\left(x\\right)$</li><li>$x^{*} = arg \\min_{x \\in X} f\\left(x\\right)$</li></ul> | minimizador con restricciones |\n","| <ul><li>$f\\left(x^{*}\\right) = \\min_{x} f\\left(x\\right)$</li><li>$x^{*} = arg \\min_{x} f\\left(x\\right)$</li></ul>       | minimizador sin restricciones |\n","\n","donde $arg \\min$ significa: \"el argumento que minimiza la función $f$; es decir un puntoen el dominio de $f$\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["### Ejemplo No. 1\n","\n","Calcule el argumento que minimiza la función $f\\left(x\\right)$, (determine el resultado de manera gráfica):\n","\n","$f\\left(x\\right) = \\left(x+1\\right)^{2} + 3$"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Primero se define la función, tener en cuenta que en python es posible desarrollar funciones lambda\n","# El doble multiplicador \"**\" significa elevar a la potencia\n","# Se ha usado funciones de numpy para hacer una distribución de 100 puntos entre -3 y 1 para este ejercicio\n","\n","f = lambda x: (x+1)**2+3\n","x = np.linspace(-3.0, 1.0, 101)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Los siguientes comandos se encargarán de obtener la gráfica\n","fig, ax = plt.subplots(1, 1, figsize=(10,10))\n","ax.plot(x, f(x), lw=4)\n","ax.set_xlabel(r'$x$', fontsize=24)\n","ax.set_ylabel(r'$f\\left(x\\right)$', fontsize=24)\n","ax.set_title('Ejemplo No.1', fontsize=24)\n","ax.grid(True, lw=1.5, ls='--', alpha=0.75) # Suaviza la intensidad de la grilla\n","ax.set_xlim(x.min(), x.max())\n","ax.set_ylim(0, f(x).max())\n","ax.tick_params(labelsize=24)"]},{"cell_type":"markdown","metadata":{},"source":["### Ejemplo No. 2\n","\n","Calcule $arg \\min_{x \\in X} f\\left(x\\right)$:\n","\n","$f\\left(x\\right) = \\left(x+1\\right)^{2}+3$\n","\n","$s.t. ~ \\forall x \\geq 0$"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f = lambda x: (x+1)**2+3\n","x = np.linspace(-3.0, 1.0, 101)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Los siguientes comandos se encargarán de obtener la gráfica\n","fig, ax = plt.subplots(1, 1, figsize=(10,10))\n","ax.plot(x, f(x), lw=4)\n","ax.fill_between(x, 8, where= x >= 0, facecolor='green', alpha=0.25)\n","ax.set_xlabel(r'$x$', fontsize=24)\n","ax.set_ylabel(r'$f\\left(x\\right)$', fontsize=24)\n","ax.set_title('Ejemplo No.2', fontsize=24)\n","ax.grid(True, lw=1.5, ls='--', alpha=0.75) # Suaviza la intensidad de la grilla\n","ax.set_xlim(x.min(), x.max())\n","ax.set_ylim(0, f(x).max())\n","ax.tick_params(labelsize=24)"]},{"cell_type":"markdown","metadata":{},"source":["### Observaciones\n","\n","Estrictamente hablando, un problema de optimización es resuelto solo cuando un minimizador global es encontrado. Sin embargo, hallar el minimizador global es difícil de encontrar, por lo que en la práctica se puede dar por cumplido cuando se encuentra un mínimo local."]},{"cell_type":"markdown","metadata":{},"source":["## 2.3. Condiciones para Minimizadores Locales\n","\n","Primero, es necesario saber como derivar una función y también calcular su segunda derivada.\n","\n","La derivada de un función $f\\left(x\\right)$ por definición es:\n","\n","$\\nabla f\\left(x\\right) \\triangleq \\left[ \\frac{\\partial f\\left(x\\right)}{\\partial x_{1}}, \\frac{\\partial f\\left(x\\right)}{\\partial x_{2}}, \\ldots, \\frac{\\partial f\\left(x\\right)}{\\partial x_{n}}\\right]^{T} $\n","\n","Esto representa al **GRADIENTE**.\n","\n","La segunda derivada de $f: \\mathbb{R}^{n}\\to \\mathbb{R}$, llamada la **HESSIANA** de $f\\left(x\\right)$ es:\n","\n","$\\nabla^{2} f\\left(x\\right) =\n","    \\begin{bmatrix}\n","    \\frac{\\partial^{2} f\\left(x\\right)}{\\partial x_{1}^{2}} & \\cdots & \\frac{\\partial^{2} f\\left(x\\right)}{\\partial x_{n} \\partial x_{1}} \\\\\n","    \\vdots & & \\vdots \\\\\n","    \\frac{\\partial^{2} f\\left(x\\right)}{\\partial x_{1} \\partial x_{n}} & \\cdots & \\frac{\\partial^{2} f\\left(x\\right)}{\\partial x_{n}^{2}}\n","    \\end{bmatrix}$\n","\n","$\\nabla^{2} f\\left(x\\right) = \\nabla^{2} f\\left(x\\right)^{T}$"]},{"cell_type":"markdown","metadata":{},"source":["### Ejemplo No. 3\n","\n","Calcule el gradiente y la hessiana de la función:\n","\n","$f\\left(x_{1},x_{2}\\right)=5x_{1}+8x_{2}+x_{1}x_{2}-x_{1}^{2}-2x_{2}^2$"]},{"cell_type":"markdown","metadata":{},"source":["### Solución Ejemplo No. 3\n","\n","Indique los valores para $a_{1}$, $b_{1}$, $c_{1}$, $a_{2}$, $b_{2}$, $c_{2}$, $d_{1,1}$, $d_{1,2}$, $d_{2,1}$, $d_{2,2}$:  \n","\n","$\\nabla f\\left(x\\right) = \\left[a_{1}+b_{1}x_{1}+c_{1}x_{2},~ a_{2}+b_{2}x_{1}+c_{2}x_{2}\\right]^{T}$\n","\n","$\\nabla^{2} f\\left(x\\right) = \\begin{bmatrix} d_{1,1} & d_{1,2}\\\\ d_{2,1} & d_{2,2} \\end{bmatrix}$"]},{"cell_type":"markdown","metadata":{},"source":["Dado un problema de optimización con un conjunto de restricción $\\Omega$, el minimizador podría estar ubicado en el interior o sobre los límites de $\\Omega$. Para estudiar el caso donde este cae sobre el límite, es necesario conocer la noción de *direcciones factibles*.\n","\n","<center>\n","<img src=\"https://drive.google.com/uc?id=12xuefP0mFW88s0-nJbHxmVQvbjRTPI-8\" height=\"350\"><br>\n","</center>\n","\n","En la figura, $d_{1}$ es una dirección factible; $d_{2}$ es una dirección no factible.\n","\n","**Definición:** Un vector $d \\in \\mathbb{R}^{n}$, $d\\neq 0$, es una dirección factible de $x \\in \\Omega$ si existe un $\\alpha_{0}>0$, tal que $x+\\alpha d \\in \\Omega$ para todo $\\alpha \\in \\left[0,~ \\alpha_{0}\\right]$\n","\n","Sea $f:\\mathbb{R}^{n}\\to \\mathbb{R}$ una función y $d$ una dirección factible de $x \\in \\Omega$, la derivada direccional de $f\\left(x\\right)$ en la dirección $d$, denotada como $\\frac{\\partial f\\left(x\\right)}{\\partial d}$, es una función definida por:\n","\n","$\\frac{\\partial f}{\\partial d} \\left(x\\right) = \\lim_{\\alpha \\to 0} \\frac{f\\left(x+\\alpha d\\right)-f\\left(x\\right)}{\\alpha}$\n","\n","Si $\\| d \\|=1$, entonces $\\frac{\\partial f}{\\partial d}$ es la tasa de incremento de $f$ en $x$ en la dirección $d$. Para calcular la derivada direccional, suponga que $x$ y $d$ están dados, por lo que se simplifica a la forma:\n","\n","$\\frac{\\partial f}{\\partial d}\\left(x\\right) =\\left. {\\frac{\\delta}{\\delta \\alpha} f\\left(x+\\alpha d\\right)}\\right| _{\\alpha=0} $\n","\n","Aplicando la regla de la cadena produce:\n","\n","$\\frac{\\partial f}{\\partial d} \\left(x\\right) = \\left.{\\frac{\\delta}{\\delta \\alpha} f\\left(x+\\alpha d\\right)}\\right|_{\\alpha=0} = \\nabla f\\left(x\\right)^{T} d = \\langle \\nabla f\\left(x\\right), d \\rangle = d^{T}\\nabla f\\left(x\\right)$\n","\n","En resumen, si $d$ es un vector unitario (\\|d\\|=1), entonces $\\langle \\nabla f\\left(x\\right), d\\rangle$ es la tasa de incremento de $f$ en el punto $x$ en la dirección $d$."]},{"cell_type":"markdown","metadata":{},"source":["### Ejemplo No. 4\n","\n","Siendo $f:\\mathbb{R}^{3}\\to \\mathbb{R}$ una función definida como:\n","\n","$f\\left(x\\right) = x_{1}x_{2}x_{3}$ \n","\n","y sea:\n","\n","$d = \\left[\\frac{1}{2},~ \\frac{1}{2},~ \\frac{1}{\\sqrt{2}},\\right]^{T}$\n","\n","Calcule la derivada direccional de $f$ en la dirección $d$"]},{"cell_type":"markdown","metadata":{},"source":["### Solución al Ejemplo No. 4\n","\n","$\\frac{\\partial f}{\\partial d} \\left(x\\right) = \\nabla f\\left(x\\right)^{T} d = \\left[\\frac{\\partial f\\left(x\\right)}{\\partial x_{1}} ,\\frac{\\partial f\\left(x\\right)}{\\partial x_{2}} ,\\frac{\\partial f\\left(x\\right)}{\\partial x_{3}} \\right] \\cdot \\begin{bmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\frac{1}{\\sqrt{2}} \\end{bmatrix} = $\n","\n","Note que $\\|d\\| = 1$, por lo tanto este valor corresponde también a la tasa de incremento de $f$ en $x$ en la dirección $d$."]},{"cell_type":"markdown","metadata":{},"source":["# 3. Condiciones de Optimalidad\n","\n","## 3.1. Condiciones Necesarias para Optimalidad\n","\n","Si la función de costo es diferenciable, nosotros podemos usar gradientes y expansiones de la serie de Taylor para comparar el costo de un vector con el costo de sus vecinos más cercanos.\n","\n","Usando una aproximación de primer orden, se produce una variación en la función de costo:\n","\n","$f\\left(x^{*}+\\Delta x\\right)-f\\left(x^{*}\\right) \\approx \\nabla f\\left(x^{*}\\right)^{T} \\Delta x$\n","\n","y con la aproximación de segundo orden, se produce una variación:\n","\n","$f\\left(x^{*}+\\Delta x\\right)-f\\left(x^{*}\\right) \\approx \\nabla f\\left(x^{*}\\right)^{T} \\Delta x + \\frac{1}{2}\\Delta x^{T} \\nabla^{2} f\\left(x^{*}\\right) \\Delta x$\n","\n","Esperamos que si $x^{*}$ es un mínimo local sin restricciones, *la variación de la función de costo de primer orden* debido a una pequeña variación $\\Delta x$ es **no-negativa**:\n","\n","$\\nabla f\\left(x^{*}\\right)^{T}\\Delta X = \\sum_{i=1}^{n} \\frac{\\partial f\\left(x^{*}\\right)}{\\partial x_{i}}\\Delta x_{i} \\geq 0$\n","\n","Note que el resultado anterior se deriva de la dirección factible calculada anteriormente:\n","\n","$d^{T}\\nabla f\\left(x^{*}\\right) \\geq 0$\n","\n","Básicamente se puede identificar un minimizador local $x^{*}$ de $f$ si para cualquier dirección $d$ su resultado es *no-negativo*.\n","\n","Supongamos que $\\Delta x = e_{k}$. Sea $e_{k} = \\left[0,~ 0, \\cdots,~ 1, \\cdots, 0\\right]^{T} \\in \\mathbb{R}^{n}$\n","\n","1. $\\nabla f\\left(x^{*}\\right)^{T}e_{k} \\geq 0 \\Rightarrow \\frac{\\partial f\\left(x\\right)}{\\partial x} \\geq 0$\n","2. $\\nabla f\\left(x^{*}\\right)^{T}\\left(-e_{k}\\right) \\geq 0 \\Rightarrow \\frac{\\partial f\\left(x\\right)}{\\partial x} < 0$\n","\n","De lo anterior se deduce que **la condición necesaria de primer orden** sólo se cumple cuando:\n","\n","$\\nabla f\\left(x^{*}\\right) = 0$\n","\n","También esperamos que la variación de la función de costo de segundo orden debido a pequeñas variaciones de $\\Delta x$ deben ser no-negativas:\n","\n","$f\\left(x^{*}+\\Delta x\\right)-f\\left(x^{*}\\right) \\approx \\nabla f\\left(x^{*}\\right)^{T} \\Delta x + \\frac{1}{2}\\Delta x^{T} \\nabla^{2} f\\left(x^{*}\\right) \\Delta x \\geq 0$\n","\n","Ya que $\\nabla f\\left(x^{*}\\right)^{T}\\Delta x = 0$, nosotros obtenemos:\n","\n","$\\Delta x^{T} \\nabla^{2} f\\left(x^{*}\\right) \\Delta x \\geq 0$\n","\n","Lo cual implica que $\\nabla^{2} f\\left(x^{*}\\right)$ es una matriz positiva semidefinida. Por lo tanto, si $x^{*}$ es un mínimo local, se debe cumplir esta condición, que se reconoce como **la condición necesaria de segundo orden**.\n","\n","**Matriz Positiva Definida**\n","\n","$x^{T}Ax > 0 ~ \\forall x\\in \\mathbb{R}^{n},~ x \\neq 0$ \n","\n","**Matriz No-negativa definida o Positiva semi-definida**\n","\n","$x^{T}Ax \\geq 0 ~ \\forall x\\in \\mathbb{R}^{n}$\n","\n","Adicionalmente, una matriz simétrica cuadrada es no-negativa definida (positiva definida) *sí y solo sí* todos sus valores propios (eigen-values) son no-negativos (positivos)\n","\n","Para que $\\lambda$ sea un valor propio es necesario y suficiente que la matriz:\n","\n","$\\lambda \\mathbb{I}-A$ sea singular (no-invertible)\n","\n","esto es,\n","\n","$|\\lambda \\mathbb{I}-A| = 0$, que denota al determinante de la matriz e $\\mathbb{I}$ representa la matriz identidad.\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2. Condiciones Suficientes de Optimalidad (Parte I)\n","\n","Suponga que tenemos un vector $x^{*}$ que satisface la condición necesaria de optimalidad de primer orden:\n","\n","$\\nabla f\\left(x^{*}\\right)=0$\n","\n","y satisface la forma fortalecida de la condición necesaria de optimalidad de segundo orden, es decir:\n","\n","$\\nabla^{2} f\\left(x^{*}\\right) |\\ \\text{sea positiva definida} ~ \\forall x,~ \\Delta x \\neq 0$\n","\n","$\\Delta x^{T} \\nabla^{2} f\\left(x^{*}\\right) \\Delta x >0$\n","\n","Lo que indica que para $x^{*}$ la variación de segundo orden de $f$ debido a pequeñas variaciones (no cero) de $\\Delta x$ son siempre positivas. Lo anterior, también sugiere que son **condiciones suficientes para optimalidad local de $x^{*}$**.\n","\n","Los mínimos locales que no satisfacen las condiciones suficientes son llamados **singulares**. En otro caso estos son llamados **no singulares**.\n","\n","Los mínimos locales *singulares* son más difíciles de tratar por dos razones:\n","\n","1. En la ausencia de convexidad de $f$, su optimalidad no puede ser comprobada usando las condiciones suficientes.\n","2. En su vecindad, los algoritmos comunmente usados de optimización tienden a ser lentos y/o erráticos."]},{"cell_type":"markdown","metadata":{},"source":["## 3.3.(*) Conjuntos y Funciones Convexas\n","\n","### Conjunto Convexo\n","\n","**Definición:** $\\mathbb{C} \\subset \\mathbb{R}^{n}$ es un conjunto convexo, si existe un segmento de línea entre dos puntos $u,~ v \\in \\mathbb{R}^{n}$, tal que:\n","\n","$\\left\\lbrace w\\in\\mathbb{R}^{n}:\\ w= \\alpha u + \\left(1-\\alpha\\right)v,~ \\alpha\\in \\left[0,~ 1\\right]\\right\\rbrace$\n","\n","Un punto $w$ es llamado una combinación convexa de los puntos $u$ y $v$ si:\n","\n","$w,~u,~v\\in \\mathbb{C}$\n","\n","Ejemplos de conjuntos convexos:\n","\n","- [x] El conjunto vacío\n","- [x] Un conjunto de un solo punto\n","- [x] Una línea o un segmento de línea\n","- [x] Un sub-espacio\n","- [x] Un hiperplano\n","- [x] Una variación lineal\n","- [x] Un espacio medio\n","- [x] $\\mathbb{R}^{n}$\n","\n","<center>\n","<img src=\"https://qph.fs.quoracdn.net/main-qimg-c0536bfb956599d4ed4b6ef375c0ae4b.webp\" height=\"350\">\n","</center>\n","\n","### Función Convexa\n","\n","Cuando una función de costo es convexa, se cumple que no existe distinción entre mínimo local y mínimo global; es decir, cada mínimo local es también un mínimo global.\n","\n","Otro aspecto importante es que la condición de primer orden $\\nabla f\\left(x^{*}\\right)=0$ es también una condición suficiente para optimalidad si $f$ es convexa.\n","\n","En general, una función de costo convexa se puede representar así:\n","\n","<center>\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d6/Convex_Function.png\" height=\"350\">\n","</center>\n","\n","$f\\left(tx+\\left(1-t\\right)y\\right) \\leq t\\cdot f\\left(x\\right)+(1-t)\\cdot f\\left(y\\right)<f\\left(y\\right),~ \\forall x,~y \\in \\mathbb{X},~ \\text{y}~ \\forall t \\in\\left[0,~1\\right] $\n","\n","De hecho, $f$ es convexa sobre $\\mathbb{X}$ *sí y solo sí*:\n","\n","$f\\left(y\\right)\\geq f\\left(x\\right)+ \\nabla f\\left(x\\right)^{T}\\left(y-x\\right),~ \\forall x,~y \\in \\mathbb{X}$\n","\n","Esto último se conoce como la aproximación lineal de un punto $x$ basado en el gradiente (Serie de Taylor de primer orden).\n","\n","**Propiedades**\n","\n","> 1. Si $f$ es convexa, entonces un mínimo local es también un mínimo global. Por qué? Sin importar el tipo de función, se puede afirmar que todo mínimo global es también un mínimo local, pero **un mínimo local es también un mínimo global?**\n",">>\n",">> Para demostrar este punto, se propone el siguiente contra ejemplo:\n",">>\n",">> $\\neg global_{min} \\Rightarrow \\neg local_{min}$\n",">>\n",">> $x^{*} \\neg global \\Rightarrow \\exists \\hat{x}\\ |\\ f\\left(\\hat{x}\\right) < f\\left(x^{*}\\right)$\n",">>\n",">> Usando el principio de convexidad de las funciones:\n",">>\n",">> $f\\left(tx^{*}+\\left(1-t\\right)\\hat{x}\\right) \\leq t\\cdot f\\left(x^{*}\\right)+(1-t)\\cdot f\\left(\\hat{x}\\right),~ \\forall t \\in\\left[0,~1\\right] $\n",">>\n",">> Sin embargo,\n",">>\n",">> $f\\left(tx^{*}+\\left(1-t\\right)\\hat{x}\\right) \\leq t\\cdot f\\left(x^{*}\\right)+(1-t)\\cdot f\\left(\\hat{x}\\right) < t\\cdot f\\left(x^{*}\\right)+\\left(1-t\\right)\\cdot f\\left(x^{*}\\right)$\n",">>\n",">> $f\\left(tx^{*}+\\left(1-t\\right)\\hat{x}\\right) \\leq t\\cdot f\\left(x^{*}\\right)+(1-t)\\cdot f\\left(\\hat{x}\\right) < f\\left(x^{*}\\right)$\n",">>\n",">> Cada punto muy cercano a $x^{*}$ tiene valores menores que $f\\left(x^{*}\\right)$, por lo tanto, $x^{*} \\neg local_{min}$.\n","\n","> 2. Si $f$ es estrictamente convexa, entonces a lo sumo son mínimos globales.\n",">>\n",">> Asuma que $x,~y,~x\\neq y$, $y$ es un mínimo global.\n",">>\n",">> Se demuestra con un contra ejemplo que:\n",">>\n",">> Sea $t =\\frac{1}{2} \\Rightarrow tx+\\left(1-t\\right)y=\\frac{1}{2}\\left(x+y\\right)$\n",">>\n",">> $f\\left(\\frac{1}{2}\\left(x+y\\right)\\right)\\leq \\frac{1}{2}\\left[f\\left(x\\right)+f\\left(y\\right)\\right]<f\\left(y\\right)$\n",">>\n",">> Ya que $x\\in \\mathbb{R}^{n}$ es un mínimo global y $f\\left(x\\right)\\leq f\\left(y\\right)$. Por lo que el punto de la ecuación más a la izquierda es estrictamente más bajo que el punto más a la derecha de la ecuación. Además tenga en cuenta que la condición de desigualda \"$\\leq$\" puede cambiar a \"<\" cuando la función es estrictamente convexa.\n","\n","> 3. Existe una función $f: \\mathbb{X} \\to \\mathbb{R}$ donde $f$ es convexa y $\\mathbb{X}$ es un conjunto convexo y abierto. Por lo tanto,\n",">>\n",">> $\\nabla f\\left(x^{*}\\right) = 0  ~\\iff x^{*}\\in \\mathbb{X}$ es un mínimo global de $\\mathbb{X}$.\n",">>\n",">> Por convexidad y usando la aproximación lineal basada en el gradiente:\n",">>\n",">> $f\\left(x\\right)\\geq f\\left(x^{*}\\right)+\\nabla f\\left(x^{*}\\right)^{T}\\left(x-x^{*}\\right),~ \\forall x \\in \\mathbb{X}$\n",">>\n",">> Si $\\nabla f\\left(x^{*}\\right) = 0 \\Rightarrow f\\left(x\\right)\\geq f\\left(x^{*}\\right),~\\forall x \\in \\mathbb{X}$ y por lo tanto $x^{*}$ es un mínimo global.\n",">>\n",">> Así, se concluye que si $x^{*} \\in \\mathbb{X}$ es un mínimo global, entonces $x^{*}$ es también un mínimo local.\n",">>\n",">> **Por qué el conjunto $\\mathbb{X}$ necesita estar abierto?**\n",">>\n",">> Considere el ejemplo:\n","<center>\n","<img src=\"https://d20khd7ddkh5ls.cloudfront.net/linear_graph.jpg\" height=\"350\">\n","</center>\n",">>\n",">> Con $\\mathbb{X}$ cerrado la derivada no puede ser cero.\n",">>\n",">> Con $\\mathbb{X}$ abierto la derivada es cero en el infinito negativo."]},{"cell_type":"markdown","metadata":{},"source":["## 3.4. Condiciones Suficientes de Optimalidad (Parte II)\n","\n","Suponga que tenemos un vector $x^{*}$ tal que:\n","\n","$x^{*}\\in \\mathbb{R}^{n}$ que satisface:\n","\n","$\\nabla f\\left(x^{*}\\right)=0$\n","$\\nabla^{2} f\\left(x^{*}\\right)>0,~\\forall \\Delta x \\neq 0$ (Positiva definida)\n","\n","$\\Delta x^{T} \\nabla^{2} f\\left(x^{*}\\right) \\Delta x > 0 $, esto implica que las variaciones de segundo orden de $f$ debido a la pequeñas variaciones de $\\Delta x$, que no son cero, **son positivas**.\n","\n","$f\\left(x^{*}+\\Delta x\\right) \\approx f\\left(x^{*}\\right)+\\nabla f\\left(x^{*}\\right)^{T}\\Delta x+\\frac{1}{2}\\Delta x^{T} \\nabla^{2} f\\left(x^{*}\\right) \\Delta x$\n","\n","Entonces si,\n","\n","$f\\left(x^{*}+\\Delta x\\right)>f\\left(x^{*}\\right) \\Rightarrow x^{*}$ es un mínimo local.\n","\n","Si en un conjunto abierto $\\mathbb{X}$ con $x^{*}\\in \\mathbb{X}$ se tiene que $\\nabla f\\left(x^{*}\\right)=0$ y $\\nabla^{2} f\\left(x^{*}\\right)>0$ se dice que $x^{*}$ es un mínimo local.\n","\n","### Ejemplos de Funciones:\n","\n","\n","| Figura                   | Condiciones de Optimalidad  |\n","| ------------------------ | --------------------------- |\n","|  ![example][cell-image01]  | <ul><li> $f\\left(x\\right) = x^{2}$ </li><li>$\\nabla f\\left(x^{*}\\right)=0$</li><li>$\\nabla^{2}f\\left(x^{*}\\right)>0$</li></ul> |\n","|  ![example][cell-image02]  | <ul><li>$\\nabla f\\left(x^{*}\\right)=0$</li><li>$\\nabla^{2}f\\left(x^{*}\\right)<0$</li></ul> |\n","|  ![example][cell-image03]  | <ul><li>$\\nabla f\\left(x^{*}\\right)=0$</li><li>$\\Delta x^{T} \\nabla^{2}f\\left(x^{*}\\right)\\Delta x ??0$</li></ul> |\n","\n","\n","[cell-image01]: https://www.lindo.com/doc/online_help/lingo17_0/bmp00196.png\n","[cell-image02]: https://www.lindo.com/doc/online_help/lingo17_0/bmp00197.png\n","[cell-image03]: https://iitutor.com/wp-content/uploads/2019/03/P050501.png"]},{"cell_type":"markdown","metadata":{},"source":["## 3.5. Funciones de Costo Cuadrático\n","\n","$f\\left(x\\right)=\\frac{1}{2}x^{T}Qx-b^{T}x$\n","\n","donde $Q$ es simétrica $Q=Q^{T}$ y $b \\in \\mathbb{R}^{n}$\n","\n","Si $x^{*}$ es un mínimo local de $f$ entonces $\\nabla f\\left(x^{*}\\right)=Qx^{*}-b$ y $\\nabla^{2} f\\left(x^{*}\\right)=Q$ es semi-definida positiva $Q\\geq0$\n","\n","* Por lo tanto, si $Q$ es NO semi-definida positiva, $f$ no tiene mínimos locales.\n","* Si $Q$ es semi-definida positiva $Q\\geq 0$, entonces $f$ es convexa.\n","* Si $Q>0$, $f$ es convexa y por lo tanto el mínimo local es igual al mínimo global.\n","\n","Sin embargo, podría no existir una solución si:\n","\n","$\\nabla f\\left(x^{*}\\right) = Qx^{*}-b=0$ y se detecta que $Q$ es no invertible ($Q$ es singular, o |Q|=0)\n","\n","Pero si $Q>0$, entonces $Q^{-1}$ existe y $x^{*}=Q^{-1}\\cdot b$ es un mínimo global ($Q$ es definida positiva)."]},{"cell_type":"markdown","metadata":{},"source":["### Ejemplo Conceptual\n","\n","Evalúe los distintos casos para la función:\n","\n","$f\\left(x,~y\\right) = \\frac{1}{2}\\left(\\alpha x^{2} + \\beta y^{2}\\right) - x$\n","\n","1. Reconstruya la función en su representación cuadrática.\n","2. Verifique su comportamiento para los casos:\n","- $\\alpha>0,~\\beta>0$\n","- $\\alpha=0$\n","- $\\alpha>0,~\\beta=0$\n","- $\\alpha>0,~\\beta<0$\n","3. Asigne valores aleatorios que cumplan con los casos y presente los gráficos de cada caso.\n","\n","* (Estudie el Teorema de Rouché-Fröbenius - disponible en el Campus Virtual)"]}]}